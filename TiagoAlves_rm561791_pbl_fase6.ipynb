{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6fea5c5a",
      "metadata": {
        "id": "6fea5c5a"
      },
      "source": [
        "# Projeto Fase 6 – Rede Neural (YOLOv5 e Comparativos)\n",
        "\n",
        "Este notebook é a implementação da Fase 6 do projeto de IA da FIAP para o grupo **rede_neural_fase6**. O objetivo é demonstrar o desenvolvimento de um sistema de visão computacional utilizando **YOLOv5**, avaliando sua performance e comparando com abordagens alternativas:\n",
        "\n",
        "- YOLOv5 customizado para reconhecer dois objetos (A e B) a partir de um dataset próprio.\n",
        "- Detecção com YOLOv5 pré-treinado (baseline zero-shot).\n",
        "- Classificação de imagens com uma **CNN treinada do zero**.\n",
        "\n",
        "Prepare seu ambiente seguindo as instruções e execute cada etapa em sequência. Onde indicado, substitua pelos caminhos corretos para suas imagens no Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcb84d48",
      "metadata": {
        "id": "dcb84d48"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ## 1. Conectar ao Google Drive e preparar o dataset\n",
        "\n",
        "from google.colab import drive\n",
        "import os, glob, shutil, random\n",
        "from pathlib import Path\n",
        "\n",
        "# Montar o Google Drive (será solicitado a autorização)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ====== CONFIGURAÇÕES ======\n",
        "# Ajuste estes caminhos para as pastas no seu Drive contendo as imagens de cada classe\n",
        "ORIGEM_IMAGENS_A = '/content/drive/MyDrive/SEU_CAMINHO/objeto_A_imagens'  # substitua\n",
        "ORIGEM_IMAGENS_B = '/content/drive/MyDrive/SEU_CAMINHO/objeto_B_imagens'  # substitua\n",
        "# Se já anotou com MakeSense e tem arquivos .txt YOLO, ajuste os caminhos das labels\n",
        "ORIGEM_LABELS_A  = '/content/drive/MyDrive/SEU_CAMINHO/objeto_A_labels'   # ou deixe como '' se ainda não houver\n",
        "ORIGEM_LABELS_B  = '/content/drive/MyDrive/SEU_CAMINHO/objeto_B_labels'   # ou deixe como '' se ainda não houver\n",
        "\n",
        "# Nomes das classes\n",
        "CLASSES = ['objeto_A', 'objeto_B']\n",
        "\n",
        "# Quantidade mínima de imagens por classe (80 no total)\n",
        "N_TRAIN = 32\n",
        "N_VAL   = 4\n",
        "N_TEST  = 4\n",
        "\n",
        "# Criar estrutura de pastas do dataset\n",
        "for p in ['dataset/images/train','dataset/images/val','dataset/images/test',\n",
        "          'dataset/labels/train','dataset/labels/val','dataset/labels/test']:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "# Função para coletar imagens\n",
        "def collect_images(path, patterns=('*.jpg','*.jpeg','*.png')):\n",
        "    files = []\n",
        "    for pat in patterns:\n",
        "        files += glob.glob(os.path.join(path, '**', pat), recursive=True)\n",
        "    return sorted(files)\n",
        "\n",
        "# Coletar imagens de cada classe\n",
        "imgs_A = collect_images(ORIGEM_IMAGENS_A)\n",
        "imgs_B = collect_images(ORIGEM_IMAGENS_B)\n",
        "\n",
        "print(f'Classe A: {len(imgs_A)} imagens, Classe B: {len(imgs_B)} imagens')\n",
        "assert len(imgs_A) >= (N_TRAIN+N_VAL+N_TEST) and len(imgs_B) >= (N_TRAIN+N_VAL+N_TEST), 'Quantidade insuficiente de imagens para o mínimo exigido.'\n",
        "\n",
        "# Embaralhar e separar imagens em treino, validação e teste\n",
        "random.seed(42)\n",
        "random.shuffle(imgs_A)\n",
        "random.shuffle(imgs_B)\n",
        "\n",
        "splits = {'train': N_TRAIN, 'val': N_VAL, 'test': N_TEST}\n",
        "\n",
        "def distribute(images, labels_dir):\n",
        "    offset = 0\n",
        "    for split, qty in splits.items():\n",
        "        part = images[offset:offset+qty]\n",
        "        offset += qty\n",
        "        for img in part:\n",
        "            dest_img = f\"dataset/images/{split}/\" + os.path.basename(img)\n",
        "            shutil.copy(img, dest_img)\n",
        "            # copiar label correspondente, se existir\n",
        "            if labels_dir:\n",
        "                label_filename = os.path.splitext(os.path.basename(img))[0] + '.txt'\n",
        "                label_path = os.path.join(labels_dir, label_filename)\n",
        "                if os.path.exists(label_path):\n",
        "                    shutil.copy(label_path, f\"dataset/labels/{split}/\" + label_filename)\n",
        "\n",
        "# Distribuir imagens e (opcionalmente) labels\n",
        "distribute(imgs_A, ORIGEM_LABELS_A)\n",
        "distribute(imgs_B, ORIGEM_LABELS_B)\n",
        "\n",
        "print('Imagens copiadas para dataset/images e labels (se houver).')\n",
        "\n",
        "# Gerar arquivo dataset.yaml para YOLOv5\n",
        "yaml_content = f'# Dataset personalizado\n",
        "path: .\n",
        "train: dataset/images/train\n",
        "val: dataset/images/val\n",
        "test: dataset/images/test\n",
        "names:\n",
        "  0: {CLASSES[0]}\n",
        "  1: {CLASSES[1]}\n",
        "'\n",
        "with open('dataset.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "print(open('dataset.yaml').read())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d5f35b",
      "metadata": {
        "id": "01d5f35b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ## 2. Instalar YOLOv5\n",
        "\n",
        "# Clonar o repositório do YOLOv5 e instalar dependências\n",
        "!git clone -q https://github.com/ultralytics/yolov5.git\n",
        "%cd yolov5\n",
        "!pip install -qr requirements.txt\n",
        "print('YOLOv5 instalado.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62d7cab",
      "metadata": {
        "id": "f62d7cab"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ## 3. Treinamento do modelo (30 e 60 épocas)\n",
        "\n",
        "import time, glob, os\n",
        "\n",
        "runs_info = []\n",
        "\n",
        "def train_yolo(epochs, run_name):\n",
        "    start = time.time()\n",
        "    !python train.py --img 640 --batch 16 --epochs {epochs} --data /content/dataset.yaml --weights yolov5s.pt --name {run_name} --project runs/detect\n",
        "    duration = time.time() - start\n",
        "    exp_dir = sorted(glob.glob(f'runs/detect/{run_name}*'))[-1]\n",
        "    runs_info.append({'run': os.path.basename(exp_dir), 'epochs': epochs, 'duration_s': duration})\n",
        "\n",
        "# Treinar com 30 e 60 épocas\n",
        "train_yolo(30, 'fase6_e30')\n",
        "train_yolo(60, 'fase6_e60')\n",
        "\n",
        "print('Treinamentos concluídos. Resumo:', runs_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00cb5a24",
      "metadata": {
        "id": "00cb5a24"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ## 4. Comparar métricas dos modelos\n",
        "\n",
        "import pandas as pd, glob, os\n",
        "from pathlib import Path\n",
        "\n",
        "def extract_metrics(exp_dir):\n",
        "    csv_files = glob.glob(os.path.join(exp_dir, 'results.csv'))\n",
        "    if csv_files:\n",
        "        df = pd.read_csv(csv_files[0])\n",
        "        last_row = df.iloc[-1]\n",
        "        return {\n",
        "            'run': Path(exp_dir).name,\n",
        "            'epochs': int(last_row.get('epoch', 0)),\n",
        "            'mAP@0.5': float(last_row.get('mAP_0.5', last_row.get('metrics/mAP_0.5', 0))),\n",
        "            'mAP@0.5:0.95': float(last_row.get('mAP_0.5:0.95', last_row.get('metrics/mAP_0.5:0.95', 0))),\n",
        "            'precision': float(last_row.get('precision', last_row.get('metrics/precision', 0))),\n",
        "            'recall': float(last_row.get('recall', last_row.get('metrics/recall', 0))),\n",
        "        }\n",
        "    return None\n",
        "\n",
        "metrics_list = []\n",
        "for exp in glob.glob('runs/detect/fase6_e*'):\n",
        "    m = extract_metrics(exp)\n",
        "    if m:\n",
        "        metrics_list.append(m)\n",
        "\n",
        "pd.DataFrame(metrics_list).sort_values('mAP@0.5:0.95', ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa71cc1a",
      "metadata": {
        "id": "fa71cc1a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ## 5. Inferência no conjunto de teste e salvar imagens\n",
        "\n",
        "import glob, os\n",
        "\n",
        "best_run_dir = 'runs/detect/fase6_e60'  # ajuste conforme avaliação\n",
        "best_weights = glob.glob(os.path.join(best_run_dir, 'weights', 'best.pt'))[0]\n",
        "\n",
        "!python detect.py --weights {best_weights} --img 640 --source '/content/dataset/images/test' --name 'fase6_test_pred' --project runs/predict --save-txt --save-conf\n",
        "print('Imagens de teste processadas. Confira a pasta runs/predict/fase6_test_pred* para visualizar.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "039dc0cb",
      "metadata": {
        "id": "039dc0cb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ## 6. Baseline YOLOv5 pré-treinado (zero-shot)\n",
        "\n",
        "!python detect.py --weights yolov5s.pt --img 640 --source '/content/dataset/images/test' --name 'baseline_zeroshot' --project runs/predict\n",
        "print('Baseline concluído. Veja runs/predict/baseline_zeroshot* para resultados.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a5f7ca9",
      "metadata": {
        "id": "1a5f7ca9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ## 7. Classificação de imagens com CNN do zero\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import pathlib, os, shutil\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "\n",
        "# Definir classes\n",
        "CLASSES = ['objeto_A', 'objeto_B']\n",
        "\n",
        "# Organizar conjunto de dados em pastas por classe\n",
        "base_cls = Path('dataset_cls')\n",
        "for split in ['train','val','test']:\n",
        "    for cls in CLASSES:\n",
        "        os.makedirs(base_cls / split / cls, exist_ok=True)\n",
        "\n",
        "# Função para mover imagens\n",
        "\n",
        "def move_to_classification(split, class_name, images):\n",
        "    for img in images:\n",
        "        dest = base_cls / split / class_name / Path(img).name\n",
        "        if not dest.exists():\n",
        "            shutil.copy(img, dest)\n",
        "\n",
        "# Selecionar imagens de cada classe\n",
        "a_train = glob('dataset/images/train/*')\n",
        "v_train = glob('dataset/images/val/*')\n",
        "t_test  = glob('dataset/images/test/*')\n",
        "\n",
        "# Dividir metade/ metade (assume ordem embaralhada)\n",
        "mid_train = len(a_train)//2\n",
        "mid_val   = len(v_train)//2\n",
        "mid_test  = len(t_test)//2\n",
        "\n",
        "move_to_classification('train', CLASSES[0], a_train[:mid_train])\n",
        "move_to_classification('train', CLASSES[1], a_train[mid_train:])\n",
        "move_to_classification('val',   CLASSES[0], v_train[:mid_val])\n",
        "move_to_classification('val',   CLASSES[1], v_train[mid_val:])\n",
        "move_to_classification('test',  CLASSES[0], t_test[:mid_test])\n",
        "move_to_classification('test',  CLASSES[1], t_test[mid_test:])\n",
        "\n",
        "# Criar datasets do TensorFlow\n",
        "img_size = (224, 224)\n",
        "batch_size = 16\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(base_cls/'train', image_size=img_size, batch_size=batch_size, label_mode='categorical', seed=42)\n",
        "val_ds   = tf.keras.preprocessing.image_dataset_from_directory(base_cls/'val',   image_size=img_size, batch_size=batch_size, label_mode='categorical', seed=42)\n",
        "test_ds  = tf.keras.preprocessing.image_dataset_from_directory(base_cls/'test',  image_size=img_size, batch_size=batch_size, label_mode='categorical', seed=42)\n",
        "\n",
        "# Prefetch\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.prefetch(AUTOTUNE)\n",
        "val_ds   = val_ds.prefetch(AUTOTUNE)\n",
        "test_ds  = test_ds.prefetch(AUTOTUNE)\n",
        "\n",
        "# Modelo simples\n",
        "model = models.Sequential([\n",
        "    layers.Rescaling(1./255, input_shape=img_size + (3,)),\n",
        "    layers.Conv2D(32, 3, activation='relu'), layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu'), layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, activation='relu'), layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(CLASSES), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_ds, epochs=20, validation_data=val_ds, verbose=1)\n",
        "\n",
        "loss, acc = model.evaluate(test_ds, verbose=0)\n",
        "print(f'Acurácia no conjunto de teste: {acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aded5ce",
      "metadata": {
        "id": "4aded5ce"
      },
      "source": [
        "# 8. Conclusões e comparações\n",
        "\n",
        "- **YOLOv5 customizado**: Utilizando 30 e 60 épocas, avaliamos o desempenho em termos de mAP e balanceamos precisão/recall.\n",
        "  Mais épocas tendem a melhorar a performance, mas aumentam o tempo de treinamento. Analise os resultados para escolher o\n",
        "  modelo mais equilibrado.\n",
        "- **YOLOv5 pré-treinado (baseline)**: Aplicado diretamente sem ajustes, serve como controle para mostrar que ele não reconhece objetos específicos\n",
        "  ausentes no COCO. Espera-se mAP baixo e detecções incorretas.\n",
        "- **CNN do zero**: Treinada para classificar imagens A vs B. Útil para comparar detecção vs classificação. Fornece acurácia alta porém não\n",
        "  localiza o objeto.\n",
        "\n",
        "**Discussão**:\n",
        "\n",
        "- *Facilidade de uso/integração*: YOLOv5 é relativamente simples de treinar e utilizar para detecção. A CNN de classificação é mais simples,\n",
        "  mas limitada a saber o que sem indicar onde.\n",
        "- *Precisão*: Compare a mAP das abordagens YOLO com a acurácia da CNN. O ajuste fino do YOLO customizado deve superar o baseline.\n",
        "- *Tempo de treinamento*: YOLOv5 com 60 épocas leva aproximadamente o dobro do tempo de 30 épocas. A CNN é mais rápida, porém depende do tamanho do dataset.\n",
        "- *Tempo de inferência*: YOLOv5 processa a localização e pode ser mais lento, enquanto a CNN classifica rapidamente.\n",
        "\n",
        "Inclua prints de predições do YOLO customizado em imagens de teste na documentação e no vídeo final para convencer o cliente da eficácia do sistema."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}